{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 7\n",
    "This assignment covers the overall concepts of Neural Networks and Convolutional Neural Networks.  \n",
    "\n",
    "\n",
    "## Install Tensorflow \n",
    "\n",
    "If ```import tensorflow as tf```  gives Module not found error then it means tensorflow is not installed.\n",
    "\n",
    "conda: ```conda create -n tf tensorflow  \n",
    "conda activate tf```\n",
    "\n",
    "pip: ```pip install tensorflow```\n",
    "\n",
    "## Tutorials\n",
    "\n",
    "* [Tensorflow Quickstart](https://www.tensorflow.org/tutorials/quickstart/beginner)\n",
    "* [MNIST Basic Image Classification w Keras](https://www.tensorflow.org/tutorials/keras/classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Keep the following in mind for all notebooks you develop:\n",
    "* Structure your notebook. \n",
    "* Use headings with meaningful levels in Markdown cells, and explain the questions each piece of code is to answer or the reason it is there.\n",
    "* Make sure your notebook can always be rerun from top to bottom.\n",
    "* Please start working on this assignment as soon as possible. If you are a beginner in Python this might take a long time. One of the objectives of this assignment is to help you learn python and scikit-learn package. \n",
    "* See [README.md](../README.md) for homework submission instructions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling w Tensorflow \n",
    "\n",
    "**DO NOT ERASE MARKDOWN CELLS AND INSTRUCTIONS IN YOUR HW submission**\n",
    "\n",
    "  * **Q** - QUESTION\n",
    "  * **A** - Where to input your answer\n",
    "\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have provided a leaf dataset which contains over 1000 leaf disease images with their ground truth labels in the csv file. You will find the dataset under the data folder. Download the dataset and complete the homework as per below instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Dataset\n",
    "\n",
    "We are using [Tensorflow](https://www.tensorflow.org/tutorials/quickstart/beginner) to train an image classifier model. Tensorflow has it's own apis for creating a data pipeline which makes it easier to feed the data into a Tensorflow model. \n",
    "* To use any suitable api to create the data needs to be loaded into a Tensorflow data object. \n",
    "* See this API for help: [Directory Dataset](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory)\n",
    "* Tensorflow [Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1** Create Data pipeline using the tensorflow api from the image list and labels\n",
    "\n",
    "1. Create tensorflow train dataset (75% of the whole data)\n",
    "2. Create tensorflow validation dataset (25% of the whole data)\n",
    "3. Preprocess the dataset (Apply Horizontal and vertical flips)\n",
    "4. Resize all images to 128X128\n",
    "5. Keep the train batch size 32 and validation batch size 16\n",
    "\n",
    "**A1** Replace ??? with code in the code cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_data =\n",
    "tf_val_data = \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Visualization\n",
    "\n",
    "Before going on to form the data pipeline, lets have a look at some of the images in the dataset and visualise them with their labels. \n",
    "\n",
    "**Q2**\n",
    "\n",
    "1. Plot 16 images with their class name from the first batch of the train data (Use 4X4 plot graph)\n",
    "2. See if images are from different class. If not, modify the train and validation data so that we have different classes in every batch.\n",
    "\n",
    "**A2** Add cells as per your need below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition \n",
    "\n",
    "We use Tensorflow to define the model that is Modified LeNet inspired [Keras example](https://www.kaggle.com/niranjanjagannath/lenet-5-architecture-for-mnist-using-tensorflow). \n",
    "1. All average pooling layers have been replaced with max pooling layers\n",
    "2. The input shape is 128X128. The first convolutional layer uses \"same\" padding to ensure the data is in the same shape as it is in the paper by the time it hits the first pooling layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3** Create CNN Model on the training set, and evaluate\n",
    "1. The model will be of 3 ConV net and followed by MaxPooling after each of them  \n",
    "* Layer 1 is a convolutional layer (ConV net): Kernel is 3X3 and number of kernel is 6 and ``relu`` as activation function\n",
    "  * Maxpool after 1st ConV net: 2X2\n",
    "  * Add 30% Dropout Layer\n",
    "* Layer 2 is a convolutional layer (ConV net): Kernel is 5X5 and number of kernel is 10 and ``relu`` as activation function\n",
    "  * Maxpool after 2nd ConV net: 2X2\n",
    "  * Add 30% Dropout Layer\n",
    "* Layer 3 is a convolutional layer (ConV net): Kernel is 5X5 and number of kernel is 16 and ``relu`` as activation function\n",
    "  * Maxpool after 2nd ConV net: 2X2\n",
    "  * Add 30% Dropout Layer\n",
    "  * Flatten this  output  \n",
    "4. Layer 4 is a dense layer with 1024 output units using ``relu`` as activation function\n",
    "5. Layer 5 is a dense layer with 512 output units using ``relu`` as activation function\n",
    "6. Layer 6 is a dense layer with 128 output units using ``relu`` as activation function\n",
    "7. Layer 7 (last layer) is a Dense Layer that is using ``softmax`` as an activation function \n",
    "\n",
    "**A3** Replace ??? with code in the code cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "\n",
    "# Fill this block with all layers\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4** Lets set an optimizer for the model training.  Use Tensorflow [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) as the optimizer with the learning rate of 0.001 and the  loss function of [sparse categorical crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy). We will keep accuracy as the evaluation measure.  Print model summary and see the number of trainable weights\n",
    "\n",
    "**A4** Replace ??? with code in the code cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = tf.keras.optimizers.?(learning_rate=?)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=?, \n",
    "    loss=?, \n",
    "    metrics=['?'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have loaded the training data, and compiled the model, now it is time to train it. The validation dataset has been included here so that the model validates its accuracy after each step by making predictions against the validation dataset.  Each epoch takes under a minute to complete so this may take a few minutes to run depending on your machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the CNN and Plot the Accuracy\n",
    "**Q5** Start the training using fit function\n",
    "1. Pass train data inside fit function\n",
    "2. Provide validation data inside fit function\n",
    "3. Define number of epochs(For faster training set it equal to 15)\n",
    "\n",
    "**A5** Replace ??? with code in the code cell below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = model.fit(\n",
    "    ?,\n",
    "    validation_data=?,\n",
    "    epochs=?\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6** Create plot on the training set, and validation set. Use ``history`` attribute from the above train_log for creating accuracy curve.\n",
    "\n",
    "\n",
    "**A6** Replace ??? with code in the code cell below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_log.??, label='accuracy')\n",
    "plt.plot(train_log.??, label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "print('Training accuracy: %f' % ?)\n",
    "print('Validation accuracy: %f' % ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot few validation set prediction\n",
    "Now that we have the trained model, lets use it to classify some images. The model will output a probability for each possible class. Numpys argmax is thus used to find the class with the highest probability and this class is used for the image.\n",
    "\n",
    "**Q7** Use the trained model to predict the first batch of the validation set\n",
    "1. Pass first batch validation data inside predict function of trained model\n",
    "2. Use numpy ``argmax`` to get the index with best classificaion score.\n",
    "3. Find the corresponding class name from the prediction class id.\n",
    "3. Plot the predicted class name with the images same as you did for the ```Q. No 2``` (Use 4X4 graph for plotting)\n",
    "\n",
    "**A7** Add any number of cells you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(??)\n",
    "predictions = np.argmax(??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Reading\n",
    "    \n",
    "* [Neural Network](https://www.bmc.com/blogs/neural-network-introduction/)\n",
    "\n",
    "* [Convolutional Neural Network](https://towardsdatascience.com/covolutional-neural-network-cb0883dd6529)\n",
    "\n",
    "* [Tensorflow Framework](https://www.datacamp.com/community/tutorials/cnn-tensorflow-python)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of CS4347-Assignment2-NETID.ipynb",
   "provenance": [
    {
     "file_id": "1vsORsvIGVbJ2cNHR1lIPDIuGobP25ZPq",
     "timestamp": 1629391503766
    },
    {
     "file_id": "1vuQua73YBPg3xOVKXACAGdS_8R1OlQdX",
     "timestamp": 1611597429764
    },
    {
     "file_id": "1Jr8VoifAgTlPqVE_AiCDeWbiHGEyvkxq",
     "timestamp": 1580784119108
    }
   ]
  },
  "interpreter": {
   "hash": "61092feec5071c5645c5e9fd8e6ed751662eaf3fad39a8c2be0e7ae1843d914b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
