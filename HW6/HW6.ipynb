{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 6\n",
    "\n",
    "This assignment covers all fundamental concepts required for completing a project\n",
    "\n",
    "**DO NOT ERASE MARKDOWN CELLS AND INSTRUCTIONS IN YOUR HW submission**\n",
    "  * **Q** - QUESTION\n",
    "  * **A** - Where to input your answer\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Keep the following in mind for all notebooks you develop:\n",
    "* Structure your notebook. \n",
    "* Use headings with meaningful levels in Markdown cells, and explain the questions each piece of code is to answer or the reason it is there.\n",
    "* Make sure your notebook can always be rerun from top to bottom.\n",
    "* Please start working on this assignment as soon as possible. If you are a beginner in Python this might take a long time. One of the objectives of this assignment is to help you learn python and scikit-learn package. \n",
    "* See [README.md](README.md) for homework submission instructions\n",
    "\n",
    "## Related Tutorials\n",
    "\n",
    "### Refreshers\n",
    "* [Intro to Machine Learning w scikit-learn](https://scikit-learn.org/stable/tutorial/basic/tutorial.html)\n",
    "* [A tutorial on statistical-learning for scientific data processing](https://scikit-learn.org/stable/tutorial/statistical_inference/index.html#stat-learn-tut-index)\n",
    " \n",
    "### Classification Approaches\n",
    "* [Logistic Regression with Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "* [KNN with sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "* [Support Vector machine example](https://scikit-learn.org/stable/auto_examples/exercises/plot_iris_exercise.html#sphx-glr-auto-examples-exercises-plot-iris-exercise-py)\n",
    "* [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html?highlight=svc#sklearn.svm.SVC)\n",
    "* [Bagging Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)\n",
    "* [Gradient Boosting Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "  \n",
    "### Modeling   \n",
    "* [Cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "* [Plot Confursion Matrix with Sklearn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)\n",
    "* [Confusion Matrix Display](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all required library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "import json\n",
    "import lightgbm as lgbm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1** Get training data from the dataframe\n",
    "1. Load ```HW6_data.csv``` from ```data``` folder into data frame\n",
    "2. Print the head of the dataframe\n",
    "3. Print the shape of the dataframe\n",
    "4. Print the description of the dataframe\n",
    "5. Check if the dataset has NULL values. (Show number of NULL values per column)\n",
    "5. Assign ```Cover_Type``` values to Y\n",
    "6. Assign rest of the column values to X\n",
    "\n",
    "**A1** Fill the cell blocks below, Create new cell as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3080.0</td>\n",
       "      <td>137</td>\n",
       "      <td>18.0</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>1009</td>\n",
       "      <td>250.0</td>\n",
       "      <td>198</td>\n",
       "      <td>166</td>\n",
       "      <td>3635.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2758.0</td>\n",
       "      <td>19</td>\n",
       "      <td>8.0</td>\n",
       "      <td>551</td>\n",
       "      <td>49</td>\n",
       "      <td>1766</td>\n",
       "      <td>225.0</td>\n",
       "      <td>231</td>\n",
       "      <td>124</td>\n",
       "      <td>1648.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2779.0</td>\n",
       "      <td>86</td>\n",
       "      <td>9.0</td>\n",
       "      <td>43</td>\n",
       "      <td>-10</td>\n",
       "      <td>3889</td>\n",
       "      <td>155.0</td>\n",
       "      <td>204</td>\n",
       "      <td>123</td>\n",
       "      <td>364.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2811.0</td>\n",
       "      <td>296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287</td>\n",
       "      <td>4</td>\n",
       "      <td>788</td>\n",
       "      <td>191.0</td>\n",
       "      <td>226</td>\n",
       "      <td>113</td>\n",
       "      <td>144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2956.0</td>\n",
       "      <td>314</td>\n",
       "      <td>26.0</td>\n",
       "      <td>71</td>\n",
       "      <td>22</td>\n",
       "      <td>2910</td>\n",
       "      <td>230.0</td>\n",
       "      <td>200</td>\n",
       "      <td>99</td>\n",
       "      <td>743.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2638.0</td>\n",
       "      <td>108</td>\n",
       "      <td>11.0</td>\n",
       "      <td>396</td>\n",
       "      <td>-6</td>\n",
       "      <td>421</td>\n",
       "      <td>198.0</td>\n",
       "      <td>218</td>\n",
       "      <td>162</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2956.0</td>\n",
       "      <td>108</td>\n",
       "      <td>29.0</td>\n",
       "      <td>291</td>\n",
       "      <td>2</td>\n",
       "      <td>2786</td>\n",
       "      <td>243.0</td>\n",
       "      <td>206</td>\n",
       "      <td>162</td>\n",
       "      <td>319.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2625.0</td>\n",
       "      <td>264</td>\n",
       "      <td>8.0</td>\n",
       "      <td>396</td>\n",
       "      <td>-6</td>\n",
       "      <td>2110</td>\n",
       "      <td>213.0</td>\n",
       "      <td>206</td>\n",
       "      <td>172</td>\n",
       "      <td>264.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2751.0</td>\n",
       "      <td>150</td>\n",
       "      <td>25.0</td>\n",
       "      <td>263</td>\n",
       "      <td>49</td>\n",
       "      <td>1234</td>\n",
       "      <td>196.0</td>\n",
       "      <td>169</td>\n",
       "      <td>154</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2947.0</td>\n",
       "      <td>83</td>\n",
       "      <td>22.0</td>\n",
       "      <td>662</td>\n",
       "      <td>-5</td>\n",
       "      <td>391</td>\n",
       "      <td>229.0</td>\n",
       "      <td>220</td>\n",
       "      <td>184</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0     3080.0     137   18.0                               166   \n",
       "1     2758.0      19    8.0                               551   \n",
       "2     2779.0      86    9.0                                43   \n",
       "3     2811.0     296    0.0                               287   \n",
       "4     2956.0     314   26.0                                71   \n",
       "5     2638.0     108   11.0                               396   \n",
       "6     2956.0     108   29.0                               291   \n",
       "7     2625.0     264    8.0                               396   \n",
       "8     2751.0     150   25.0                               263   \n",
       "9     2947.0      83   22.0                               662   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               1                             1009   \n",
       "1                              49                             1766   \n",
       "2                             -10                             3889   \n",
       "3                               4                              788   \n",
       "4                              22                             2910   \n",
       "5                              -6                              421   \n",
       "6                               2                             2786   \n",
       "7                              -6                             2110   \n",
       "8                              49                             1234   \n",
       "9                              -5                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0          250.0             198            166   \n",
       "1          225.0             231            124   \n",
       "2          155.0             204            123   \n",
       "3          191.0             226            113   \n",
       "4          230.0             200             99   \n",
       "5          198.0             218            162   \n",
       "6          243.0             206            162   \n",
       "7          213.0             206            172   \n",
       "8          196.0             169            154   \n",
       "9          229.0             220            184   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                              3635.0  ...            0            0   \n",
       "1                              1648.0  ...            0            0   \n",
       "2                               364.0  ...            0            0   \n",
       "3                               144.0  ...            0            0   \n",
       "4                               743.0  ...            0            0   \n",
       "5                              1307.0  ...            0            0   \n",
       "6                               319.0  ...            1            0   \n",
       "7                               264.0  ...            0            0   \n",
       "8                              1336.0  ...            0            0   \n",
       "9                              1566.0  ...            0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0          0.0            0            0            0   \n",
       "1            0          0.0            0            0            0   \n",
       "2            0          0.0            0            0            1   \n",
       "3            0          0.0            0            0            0   \n",
       "4            0          0.0            0            0            1   \n",
       "5            0          0.0            0            0            0   \n",
       "6            0          0.0            0            0            0   \n",
       "7            0          0.0            0            0            0   \n",
       "8            0          0.0            0            0            0   \n",
       "9            0          0.0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0          0.0           1  \n",
       "1            0          0.0           2  \n",
       "2            0          0.0           2  \n",
       "3            0          0.0           2  \n",
       "4            0          NaN           2  \n",
       "5            0          0.0           2  \n",
       "6            0          0.0           2  \n",
       "7            0          0.0           2  \n",
       "8            0          1.0           2  \n",
       "9            0          0.0           2  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can create or remove cells as per your need\n",
    "df = pd.read_csv('../data/HW6_data.csv')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 55)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>79433.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>79346.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>79200.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>78870.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>79720.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2981.436531</td>\n",
       "      <td>151.634175</td>\n",
       "      <td>15.092494</td>\n",
       "      <td>271.564212</td>\n",
       "      <td>51.510737</td>\n",
       "      <td>1770.080712</td>\n",
       "      <td>211.786818</td>\n",
       "      <td>221.069125</td>\n",
       "      <td>140.711750</td>\n",
       "      <td>1578.058615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038150</td>\n",
       "      <td>0.037687</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>0.015429</td>\n",
       "      <td>0.010812</td>\n",
       "      <td>0.012538</td>\n",
       "      <td>0.040325</td>\n",
       "      <td>0.039163</td>\n",
       "      <td>0.030707</td>\n",
       "      <td>1.770725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>287.979705</td>\n",
       "      <td>109.945631</td>\n",
       "      <td>8.528153</td>\n",
       "      <td>227.532197</td>\n",
       "      <td>68.091489</td>\n",
       "      <td>1318.661060</td>\n",
       "      <td>30.822278</td>\n",
       "      <td>22.191030</td>\n",
       "      <td>43.859689</td>\n",
       "      <td>1125.780446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191559</td>\n",
       "      <td>0.190441</td>\n",
       "      <td>0.108155</td>\n",
       "      <td>0.123252</td>\n",
       "      <td>0.103420</td>\n",
       "      <td>0.111268</td>\n",
       "      <td>0.196722</td>\n",
       "      <td>0.193983</td>\n",
       "      <td>0.172523</td>\n",
       "      <td>0.892577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1813.000000</td>\n",
       "      <td>-29.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-43.000000</td>\n",
       "      <td>-276.000000</td>\n",
       "      <td>-238.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>-48.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2762.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>821.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>782.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2967.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>1362.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3217.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>2366.000000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>2082.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4271.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1544.000000</td>\n",
       "      <td>562.000000</td>\n",
       "      <td>7604.000000</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>8011.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Elevation        Aspect         Slope  \\\n",
       "count  79433.000000  80000.000000  79346.000000   \n",
       "mean    2981.436531    151.634175     15.092494   \n",
       "std      287.979705    109.945631      8.528153   \n",
       "min     1813.000000    -29.000000     -3.000000   \n",
       "25%     2762.000000     60.000000      9.000000   \n",
       "50%     2967.000000    122.000000     14.000000   \n",
       "75%     3217.000000    246.000000     20.000000   \n",
       "max     4271.000000    400.000000     61.000000   \n",
       "\n",
       "       Horizontal_Distance_To_Hydrology  Vertical_Distance_To_Hydrology  \\\n",
       "count                      80000.000000                    80000.000000   \n",
       "mean                         271.564212                       51.510737   \n",
       "std                          227.532197                       68.091489   \n",
       "min                          -43.000000                     -276.000000   \n",
       "25%                          111.000000                        4.000000   \n",
       "50%                          212.000000                       31.000000   \n",
       "75%                          361.000000                       78.000000   \n",
       "max                         1544.000000                      562.000000   \n",
       "\n",
       "       Horizontal_Distance_To_Roadways  Hillshade_9am  Hillshade_Noon  \\\n",
       "count                     80000.000000   79200.000000    80000.000000   \n",
       "mean                       1770.080712     211.786818      221.069125   \n",
       "std                        1318.661060      30.822278       22.191030   \n",
       "min                        -238.000000      10.000000       69.000000   \n",
       "25%                         821.000000     198.000000      210.000000   \n",
       "50%                        1440.000000     218.000000      224.000000   \n",
       "75%                        2366.000000     233.000000      237.000000   \n",
       "max                        7604.000000     293.000000      264.000000   \n",
       "\n",
       "       Hillshade_3pm  Horizontal_Distance_To_Fire_Points  ...   Soil_Type32  \\\n",
       "count   80000.000000                        78870.000000  ...  80000.000000   \n",
       "mean      140.711750                         1578.058615  ...      0.038150   \n",
       "std        43.859689                         1125.780446  ...      0.191559   \n",
       "min       -48.000000                         -218.000000  ...      0.000000   \n",
       "25%       115.000000                          782.000000  ...      0.000000   \n",
       "50%       142.000000                         1362.000000  ...      0.000000   \n",
       "75%       169.000000                         2082.000000  ...      0.000000   \n",
       "max       268.000000                         8011.000000  ...      1.000000   \n",
       "\n",
       "        Soil_Type33   Soil_Type34   Soil_Type35   Soil_Type36   Soil_Type37  \\\n",
       "count  80000.000000  80000.000000  79720.000000  80000.000000  80000.000000   \n",
       "mean       0.037687      0.011838      0.015429      0.010812      0.012538   \n",
       "std        0.190441      0.108155      0.123252      0.103420      0.111268   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        Soil_Type38   Soil_Type39   Soil_Type40    Cover_Type  \n",
       "count  80000.000000  80000.000000  75000.000000  80000.000000  \n",
       "mean       0.040325      0.039163      0.030707      1.770725  \n",
       "std        0.196722      0.193983      0.172523      0.892577  \n",
       "min        0.000000      0.000000      0.000000      1.000000  \n",
       "25%        0.000000      0.000000      0.000000      1.000000  \n",
       "50%        0.000000      0.000000      0.000000      2.000000  \n",
       "75%        0.000000      0.000000      0.000000      2.000000  \n",
       "max        1.000000      1.000000      1.000000      7.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevation                              567\n",
      "Aspect                                   0\n",
      "Slope                                  654\n",
      "Horizontal_Distance_To_Hydrology         0\n",
      "Vertical_Distance_To_Hydrology           0\n",
      "Horizontal_Distance_To_Roadways          0\n",
      "Hillshade_9am                          800\n",
      "Hillshade_Noon                           0\n",
      "Hillshade_3pm                            0\n",
      "Horizontal_Distance_To_Fire_Points    1130\n",
      "Wilderness_Area1                         0\n",
      "Wilderness_Area2                         0\n",
      "Wilderness_Area3                         0\n",
      "Wilderness_Area4                         0\n",
      "Soil_Type1                               0\n",
      "Soil_Type2                               0\n",
      "Soil_Type3                               0\n",
      "Soil_Type4                               0\n",
      "Soil_Type5                               0\n",
      "Soil_Type6                               0\n",
      "Soil_Type7                               0\n",
      "Soil_Type8                               0\n",
      "Soil_Type9                               0\n",
      "Soil_Type10                              0\n",
      "Soil_Type11                              0\n",
      "Soil_Type12                              0\n",
      "Soil_Type13                              0\n",
      "Soil_Type14                              0\n",
      "Soil_Type15                              0\n",
      "Soil_Type16                              0\n",
      "Soil_Type17                              0\n",
      "Soil_Type18                              0\n",
      "Soil_Type19                              0\n",
      "Soil_Type20                              0\n",
      "Soil_Type21                              0\n",
      "Soil_Type22                              0\n",
      "Soil_Type23                              0\n",
      "Soil_Type24                              0\n",
      "Soil_Type25                              0\n",
      "Soil_Type26                              0\n",
      "Soil_Type27                              0\n",
      "Soil_Type28                              0\n",
      "Soil_Type29                              0\n",
      "Soil_Type30                              0\n",
      "Soil_Type31                              0\n",
      "Soil_Type32                              0\n",
      "Soil_Type33                              0\n",
      "Soil_Type34                              0\n",
      "Soil_Type35                            280\n",
      "Soil_Type36                              0\n",
      "Soil_Type37                              0\n",
      "Soil_Type38                              0\n",
      "Soil_Type39                              0\n",
      "Soil_Type40                           5000\n",
      "Cover_Type                               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check if there is NaN in the dataset\n",
    "print( df.isnull().sum() )\n",
    "\n",
    "#Drop NaNs if there is any\n",
    "df = df.dropna()\n",
    "\n",
    "Y= df['Cover_Type'].values\n",
    "X= df.drop( columns=['Cover_Type'] ).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** Open-Ended Questions: Observe the range of all feature values and statistical information from the dataframe description above.\n",
    "1. If the dataset has NULL values, Give proper justification about the methods you will use to replace NULL values for specific columns.  \n",
    "2. Do you think in our dataset normalization is required? -- Give proper justification based on your opinion. \n",
    "3. What type of normalization/Scaling technique you whould recommend for our dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A2** \n",
    "\n",
    "```Answer 1:``` \n",
    "I first check the dataframe for NULL values with df.isnull().sum(). I then remove the rows containing them, by setting the dataframe equal to df.dropna().\n",
    "\n",
    "```Answer 2:```\n",
    "The removal of Nan value is necessary for tuning out incomplete data and preventing data imbalance. It is also critical to have only valid values in the dataset when for numerical calculations.\n",
    "\n",
    "```Answer 3:```\n",
    "Because attributes such as elevation scale are numerically greater than most of the other attributes in the data frame, we can use the standard scaler to normalization to preserve relative relationships between attributes by scaling the features to have a near 0 mean and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3:** \n",
    "1. Replace the null values with the best possible methods from your above observation\n",
    "1. Use the above mentioned normalization technique on our HW_6 dataset.\n",
    "2. Transform the X dataframe using choosen normalization technique. \n",
    "\n",
    "### ```Note:``` Make sure the scaled X has all column name same as ```X dataframe```\n",
    "\n",
    "**A3** Fill the cell blocks below, Create new cell as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NULLs\n",
    "#You can create or remove cells as per your need\n",
    "\n",
    "# removed NULLs prior to assigning values to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "#You can create or remove cells as per your need\n",
    "scaler = StandardScaler()\n",
    "Scaled_X = scaler.fit_transform( X )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4:** \n",
    "\n",
    "1. Check again and show if there is any null values left in our ```Scaled_X```.\n",
    "2. Print all unique values/ different class id from the ```Y data```.\n",
    "\n",
    "\n",
    "**A4** Fill the cell blocks below, Create new cell as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can create or remove cells as per your need\n",
    "np.isnan( Scaled_X ).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 6, 7], dtype=int64)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique( Y ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Use a subset of whole data(N=20000) for Data Visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Subset Creation**\n",
    "\n",
    "1. First we are Selecting ```N=20000``` random rows from our original dataset which is ```df``` and create a new subset of data.\n",
    "\n",
    "2. Using the below **rndperm** and selecting first N index from the ```Scaled_X``` and ```Y```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 54)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "rndperm = np.random.permutation(df.shape[0])\n",
    "N = 20000\n",
    "data_subset_x = Scaled_X[rndperm[:N],:].copy()\n",
    "data_subset_y = Y[rndperm[:N]].copy()\n",
    "\n",
    "print( data_subset_x.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5:**\n",
    "\n",
    "1. Use PCA and reduce the dimension of the **data_subset_x** into ```3```.\n",
    "2. Store the PCA reuslt into ```pca_result``` variable\n",
    "3. Add the results from the PCA into the **data_subset_x** as new columns. (Choose any meaningful names for the columns) \n",
    "\n",
    "\n",
    "**A5** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 3)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can create or remove cells as per your need\n",
    "pca = PCA( n_components=3 )\n",
    "pca_result = pca.fit_transform( data_subset_x )\n",
    "pca_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame( pca_result, columns=[ 'PCA_Component_1', 'PCA_Component_2', 'PCA_Component_3' ] )\n",
    "\n",
    "# Concatenate pca_df with data_subset_x along the columns axis\n",
    "data_subset_x = np.concatenate( (data_subset_x, pca_df), axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6:**\n",
    "\n",
    "1. Use TSNE and reduce the dimension of the **data_subset_x** into ```2```.\n",
    "2. Store the TSNE reuslt into ```tsne_results``` variable\n",
    "3. Add the resutls from the T-SNE into the **data_subset_x** as new columns. (Choose any meaningful names for the columns) \n",
    "\n",
    "\n",
    "```Note:``` \n",
    "1. You can use ```from sklearn.manifold import TSNE``` for TSNE initialization.\n",
    "2. Give value of n_components as per the question.\n",
    "3. Also use other parameters while TSNE initialization as, ```verbose=1, perplexity=40, n_iter=300```\n",
    "\n",
    "**A6** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 20000 samples in 0.002s...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computed neighbors for 20000 samples in 0.861s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 15000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 16000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 17000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 18000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 19000 / 20000\n",
      "[t-SNE] Computed conditional probabilities for sample 20000 / 20000\n",
      "[t-SNE] Mean sigma: 1.308954\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 77.059135\n",
      "[t-SNE] KL divergence after 300 iterations: 2.922222\n"
     ]
    }
   ],
   "source": [
    "#You can create or remove cells as per your need\n",
    "tsne = TSNE( n_components=2, verbose=1, perplexity=40, n_iter=300 )\n",
    "tsne_results = tsne.fit_transform( data_subset_x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = pd.DataFrame(tsne_results, columns=['TSNE_Component_1', 'TSNE_Component_2'])\n",
    "\n",
    "# Concatenate data_subset_x with tsne_df along the columns axis\n",
    "data_subset_x = np.concatenate((data_subset_x, tsne_df), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7:**\n",
    "\n",
    "1. Create a new dataframe with name ```df_plot```\n",
    "2. This dataframe will merge everything from **data_subset_x** and **data_subset_y**\n",
    "3. We need to give a name for the ```data_subset_y``` column. Use ```Cover_Type``` as the name of the column\n",
    "\n",
    "\n",
    "**A7** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1356688067.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[223], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    df_plot=\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df_plot=\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8:** Now we will plot all points from our dataframe ```df_plot``` Using the result from **PCA**\n",
    "\n",
    "1. Use ```pca-one``` and ```pca-two``` column as X and Y axis respectively.\n",
    "2. Use seaborn scatterplot for plotting the points.\n",
    "\n",
    "```Note:``` Use the notebook from class for reference. The link is provided below.\n",
    "\n",
    "```Link:``` https://git.txstate.edu/ML/2022Fall/blob/main/project/Data_Viz_with_PCA_TSNE.ipynb\n",
    "\n",
    "**A8** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9:** Now we will plot all points from our dataframe ```df_plot``` Using result from T-SNE.\n",
    "\n",
    "1. Use ```tsne-2d-one``` and ```tsne-2d-one``` column as X and Y axis respectively.\n",
    "2. Use seaborn scatterplot for plotting the points.\n",
    "\n",
    "\n",
    "```Note:``` Use the notebook from class for reference. The link is provided below.\n",
    "\n",
    "```Link:``` https://git.txstate.edu/ML/2022Fall/blob/main/project/Data_Viz_with_PCA_TSNE.ipynb\n",
    "\n",
    "**A9** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Analysis and Classification Using Entire Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10:** Observe the data plotting and find the realtion between datapoints and their characteristics.\n",
    "\n",
    "\n",
    "1. Reduce the dimension of our ```Scaled_X``` dataframe to ```3``` using PCA algorithm.\n",
    "2. Store the result into a variable named ```pca_result```\n",
    "3. Create Train data and Test data using the pca_result and Y.\n",
    "\n",
    "```Note:``` \n",
    "1. Consider pca_result as X values, and Y as y values.\n",
    "2. You can use sklearn train_test_split\n",
    "3. Keep Train and Test ratio as : 75%:25%\n",
    "\n",
    "**A10** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need\n",
    "pca = \n",
    "pca_result = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, Select Three best model for our dataset. You have to decide three models which might work well with our dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsUM8-i_KhK1"
   },
   "source": [
    "**Q11** \n",
    "\n",
    "**Model Number 1** \n",
    "\n",
    "1. Reason behind choosing the model.\n",
    "2. Create the model using sklearn or any proper library\n",
    "3. Fit the model with the train data \n",
    "4. Get the score from the model using test data\n",
    "\n",
    "**A11** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Answer for Q.No:1 goes here```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QutY2XJWps5"
   },
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12** \n",
    "\n",
    "**Model Number 2** \n",
    "\n",
    "1. Reason behind choosing the model.\n",
    "2. Create the model using sklearn or any proper library\n",
    "3. Fit the model with the train data \n",
    "4. Get the score from the model using test data\n",
    "\n",
    "**A12** Fill the below cells. Use extra cells as per your necessaryReplace ??? with code in the code cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Answer for Q.No:1 goes here```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13** \n",
    "\n",
    "**Model Number 3** \n",
    "\n",
    "1. Reason behind choosing the model.\n",
    "2. Create the model using sklearn or any proper library\n",
    "3. Fit the model with the train data \n",
    "4. Get the score from the model using test data\n",
    "\n",
    "**A13** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Answer for Q.No:1 goes here```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14** \n",
    "\n",
    "\n",
    "1. Plot a histogram using Y dataframe and display the per-class data distribution(number of rows per class).\n",
    "2. Also print the number of rows per class as numeric value.\n",
    "\n",
    "**A14** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15** \n",
    "\n",
    "\n",
    "1. From the histogram we can see that the dataset is highly imbalanced.\n",
    "2. Use a proper dataset balancing technique to make the dataset balanced.\n",
    "3. Plot a histogram using new y values and display the per-class data distribution(number of rows per class).\n",
    "\n",
    "```Note:``` Use can use the ```imblearn.over_sampling``` library for this task. But use appropriate strategy for the method.\n",
    "\n",
    "Follow the documentation for details: https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html\n",
    "\n",
    "**A15** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need\n",
    "\n",
    "?\n",
    "X_res, y_res="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q16** \n",
    "\n",
    "\n",
    "1. Create new Train and Test data from the balaned X and Y value.\n",
    "2. Keep Train and Test ratio as : 75%:25%\n",
    "\n",
    "**A16** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q17**\n",
    "\n",
    "### Now, Use the previously initialized three models and calculate the score from our new balanced dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Number 1** \n",
    "\n",
    "1. Fit the model with the new train data(Use the previous Model 1) \n",
    "2. Get the score from the model using  new test data\n",
    "\n",
    "**A17** Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Number 2** \n",
    "\n",
    "1. Fit the model with the new train data(Use the previous Model 2) \n",
    "2. Get the score from the model using  new test data\n",
    "\n",
    "Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Number 3** \n",
    "\n",
    "1. Fit the model with the new train data(Use the previous Model 3) \n",
    "2. Get the score from the model using  new test data\n",
    "\n",
    "Fill the below cells. Use extra cells as per your necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can create or remove cells as per your need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After making the dataset balanced we can see a significant improve in the performence for all three models."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of CS4347-Assignment2-NETID.ipynb",
   "provenance": [
    {
     "file_id": "1vsORsvIGVbJ2cNHR1lIPDIuGobP25ZPq",
     "timestamp": 1629391503766
    },
    {
     "file_id": "1vuQua73YBPg3xOVKXACAGdS_8R1OlQdX",
     "timestamp": 1611597429764
    },
    {
     "file_id": "1Jr8VoifAgTlPqVE_AiCDeWbiHGEyvkxq",
     "timestamp": 1580784119108
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e3520c759e5572dcce85a4d2a3287416a08b75cbd9d64f3e9845a08c03ad027"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
